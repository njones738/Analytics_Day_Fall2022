{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notebook Parameters\n",
    "\n",
    "fold_pth = \"N:/Code/GITHUB/Analytics_Day/Analytics_Day_Fall2022/\" + \"/data/\"\n",
    "\n",
    "input_data_name = \"MERGED_PP\" + \".csv\"\n",
    "\n",
    "output_data_name = \"ratemyprof_reviews\" + \".csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class Creation\n",
    "\n",
    "import requests, json, math, csv, os\n",
    "import pandas as pd\n",
    "\n",
    "from professor import Professor\n",
    "# This code has been tested using Python 3.6 interpreter and Linux (Ubuntu).\n",
    "# It should run under Windows, if anything you may need to make some adjustments for the file paths of the CSV files.\n",
    "\n",
    "\n",
    "class ProfessorNotFound(Exception):\n",
    "    def __init__(self, search_argument, search_parameter: str = \"Name\"):\n",
    "\n",
    "        # What the client is looking for. Ex: \"Professor Pattis\"\n",
    "        self.search_argument = self.search_argument\n",
    "\n",
    "        # The search criteria. Ex: Last Name\n",
    "        self.search_parameter = search_parameter\n",
    "\n",
    "    def __str__(self):\n",
    "\n",
    "        return (\n",
    "            f\"Proessor not found\"\n",
    "            + f\" The search argument {self.search_argument} did not\"\n",
    "            + f\" match with any professor's {self.search_parameter}\"\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "class RateMyProfApi:\n",
    "\n",
    "    def __init__(self, school_id: str = \"1074\", testing: bool = False, prnt = True):\n",
    "        self.prnt = prnt\n",
    "        self.UniversityId = school_id\n",
    "        if not os.path.exists(\"SchoolID_\" + str(self.UniversityId)):\n",
    "            os.mkdir(\"SchoolID_\" + str(self.UniversityId))\n",
    "\n",
    "        # dict of Professor\n",
    "        self.professors= self.scrape_professors(testing)\n",
    "        self.indexnumber = False\n",
    "\n",
    "    def scrape_professors(self, testing: bool = False):  # creates List object that include basic information on all Professors from the IDed University\n",
    "        professors = dict()\n",
    "        num_of_prof = self.get_num_of_professors(self.UniversityId)\n",
    "        num_of_pages = math.ceil(num_of_prof / 20)\n",
    "        temp_lst = []\n",
    "        for i in range(1, num_of_pages + 1):  # the loop insert all professor into list\n",
    "            page = requests.get(\n",
    "                \"http://www.ratemyprofessors.com/filter/professor/?&page=\"\n",
    "                + str(i)\n",
    "                + \"&filter=teacherlastname_sort_s+asc&query=*%3A*&queryoption=TEACHER&queryBy=schoolId&sid=\"\n",
    "                + str(self.UniversityId)\n",
    "            )\n",
    "            json_response = json.loads(page.content)\n",
    "            temp_list = json_response[\"professors\"]\n",
    "\n",
    "            temp_lst.append(json_response)\n",
    "\n",
    "            for json_professor in json_response[\"professors\"]:\n",
    "                if self.prnt == True:\n",
    "                    print(json_professor)\n",
    "                professor = Professor(\n",
    "                    json_professor[\"tid\"],\n",
    "                    json_professor[\"tFname\"],\n",
    "                    json_professor[\"tLname\"],\n",
    "                    json_professor[\"tNumRatings\"],\n",
    "                    json_professor[\"overall_rating\"])\n",
    "\n",
    "                professors[professor.ratemyprof_id] = professor\n",
    "\n",
    "            # for test cases, limit to 2 iterations\n",
    "            if testing and (i > 1): break\n",
    "\n",
    "        return professors\n",
    "\n",
    "    def get_num_of_professors(self, id):  # function returns the number of professors in the university of the given ID.\n",
    "        page = requests.get(\n",
    "            \"http://www.ratemyprofessors.com/filter/professor/?&page=1&filter=teacherlastname_sort_s+asc&query=*%3A*&queryoption=TEACHER&queryBy=schoolId&sid=\"\n",
    "            + str(id))  # get request for page\n",
    "\n",
    "        temp_jsonpage = json.loads(page.content)\n",
    "\n",
    "        num_of_prof = (temp_jsonpage[\"remaining\"] + 20)  # get the number of professors at William Paterson University\n",
    "\n",
    "        return num_of_prof\n",
    "\n",
    "    def search_professor(self, ProfessorName):\n",
    "        self.indexnumber = self.get_professor_by_last_name(ProfessorName)\n",
    "        self.print_professor_info()\n",
    "        return self.indexnumber\n",
    "\n",
    "    def get_professor_by_last_name(\n",
    "        self, last_name\n",
    "    ) -> Professor:\n",
    "        '''\n",
    "        Return the first professor with the matching last name.\n",
    "        Case insenstive.\n",
    "        '''\n",
    "        last_name = last_name.lower()\n",
    "        for name in professors:\n",
    "            if last_name == professors[name].last_name.lower():\n",
    "                return professors[name]\n",
    "\n",
    "        # Raise error if no matching professor found\n",
    "        raise ProfessorNotFound(last_name, \"Last Name\")\n",
    "\n",
    "    def WriteProfessorListToCSV(self):\n",
    "        csv_columns = [\n",
    "            \"tDept\",\n",
    "            \"tSid\",\n",
    "            \"institution_name\",\n",
    "            \"tFname\",\n",
    "            \"tMiddlename\",\n",
    "            \"tLname\",\n",
    "            \"tid\",\n",
    "            \"tNumRatings\",\n",
    "            \"rating_class\",\n",
    "            \"contentType\",\n",
    "            \"categoryType\",\n",
    "            \"overall_rating\",\n",
    "        ]\n",
    "        csv_file = \"SchoolID_\" + str(self.UniversityId) + \".csv\"\n",
    "        with open(csv_file, \"w\") as csvfile:\n",
    "            writer = csv.DictWriter(csvfile, fieldnames=csv_columns)\n",
    "            writer.writeheader()\n",
    "            for data in self.professorlist:\n",
    "                writer.writerow(data)\n",
    "\n",
    "    def create_reviews_list(self, tid):\n",
    "        tempreviewslist = []\n",
    "        num_of_reviews = self.get_num_of_reviews(tid)\n",
    "        # RMP only loads 20 reviews per page,\n",
    "        # so num_of_pages tells us how many pages we need to get all the reviews\n",
    "        num_of_pages = math.ceil(num_of_reviews / 20)\n",
    "        i = 1\n",
    "        while i <= num_of_pages:\n",
    "            page = requests.get(\n",
    "                \"https://www.ratemyprofessors.com/paginate/professors/ratings?tid=\"\n",
    "                + str(tid)\n",
    "                + \"&filter=&courseCode=&page=\"\n",
    "                + str(i)\n",
    "            )\n",
    "            temp_jsonpage = json.loads(page.content)\n",
    "            temp_list = temp_jsonpage[\"ratings\"]\n",
    "            tempreviewslist.extend(temp_list)\n",
    "            i += 1\n",
    "        return tempreviewslist\n",
    "\n",
    "    def get_num_of_reviews(self, id):\n",
    "        page = requests.get(\n",
    "            \"https://www.ratemyprofessors.com/paginate/professors/ratings?tid=\"\n",
    "            + str(id)\n",
    "            + \"&filter=&courseCode=&page=1\"\n",
    "        )\n",
    "        temp_jsonpage = json.loads(page.content)\n",
    "        num_of_reviews = temp_jsonpage[\"remaining\"] + 20\n",
    "        return num_of_reviews\n",
    "\n",
    "    def WriteReviewsListToCSV(self, rlist, tid):\n",
    "        csv_columns = [\n",
    "            \"attendance\",\n",
    "            \"clarityColor\",\n",
    "            \"easyColor\",\n",
    "            \"helpColor\",\n",
    "            \"helpCount\",\n",
    "            \"id\",\n",
    "            \"notHelpCount\",\n",
    "            \"onlineClass\",\n",
    "            \"quality\",\n",
    "            \"rClarity\",\n",
    "            \"rClass\",\n",
    "            \"rComments\",\n",
    "            \"rDate\",\n",
    "            \"rEasy\",\n",
    "            \"rEasyString\",\n",
    "            \"rErrorMsg\",\n",
    "            \"rHelpful\",\n",
    "            \"rInterest\",\n",
    "            \"rOverall\",\n",
    "            \"rOverallString\",\n",
    "            \"rStatus\",\n",
    "            \"rTextBookUse\",\n",
    "            \"rTimestamp\",\n",
    "            \"rWouldTakeAgain\",\n",
    "            \"sId\",\n",
    "            \"takenForCredit\",\n",
    "            \"teacher\",\n",
    "            \"teacherGrade\",\n",
    "            \"teacherRatingTags\",\n",
    "            \"unUsefulGrouping\",\n",
    "            \"usefulGrouping\",\n",
    "        ]\n",
    "        csv_file = (\n",
    "            \"SchoolID_\" + str(self.UniversityId) + \"/TeacherID_\" + str(tid) + \".csv\"\n",
    "        )\n",
    "        with open(csv_file, \"w\") as csvfile:\n",
    "            writer = csv.DictWriter(csvfile, fieldnames=csv_columns)\n",
    "            writer.writeheader()\n",
    "            for data in rlist:\n",
    "                writer.writerow(data)\n",
    "\n",
    "## example\n",
    "# uci = RateMyProfApi(1074)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions\n",
    "\n",
    "def get_ratemyprof_sid(school_name):\n",
    "    import requests\n",
    "    from bs4 import BeautifulSoup\n",
    "    url = \"https://www.ratemyprofessors.com/search/schools?query=\" + str(school_name).replace(\" \", \"%20\")\n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.text, \"html.parser\")\n",
    "    links = [x.get(\"href\") for x in soup.find_all(\"a\")]\n",
    "    sublinks = [x for x in links if str(x).__contains__(\"school?sid\")]\n",
    "    if len(sublinks) > 0:\n",
    "        return sublinks[0]\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def get_prof_review_list(school, x):\n",
    "    try:\n",
    "        outs = school.create_reviews_list(x)\n",
    "    except:\n",
    "        outs = None\n",
    "    return outs\n",
    "\n",
    "def get_prof_reviews(professor_tid, school_sid, school):\n",
    "    prof_reviews = get_prof_review_list(school, professor_tid)\n",
    "\n",
    "    if prof_reviews != None:\n",
    "        prof_reviews = pd.json_normalize(prof_reviews)\n",
    "        prof_reviews[\"professor_tid\"] = professor_tid\n",
    "        prof_reviews[\"school_sid\"] = school_sid\n",
    "    \n",
    "    return prof_reviews\n",
    "\n",
    "def get_school_reviews(school_sid):\n",
    "    # Create a School's object and scrape the professors at the school\n",
    "    school = RateMyProfApi(school_sid, prnt = False)\n",
    "    prof = school.professors\n",
    "\n",
    "    # Scrape the reviews for each professor\n",
    "    temp_list = [get_prof_reviews(professor_tid, school_sid, school) for professor_tid in prof]\n",
    "    if temp_list != []:\n",
    "        prof_review_df = pd.concat(temp_list)\n",
    "    else:\n",
    "        prof_review_df = pd.DataFrame()\n",
    "    return prof_review_df\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Import\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "df = pd.read_csv(fold_pth + input_data_name, index_col = 0, low_memory=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the School's RateMyProfessor ID by searching RMP and pulling the SID for the top result.\n",
    "\n",
    "rmp_df = pd.DataFrame([[school_name, get_ratemyprof_sid(school_name)] for school_name in df.INSTNM.drop_duplicates().tolist()], columns = [\"INSTNM\", \"ratemyprof_sid\"])\n",
    "rmp_df = rmp_df[rmp_df[\"ratemyprof_sid\"].isna() == False]\n",
    "rmp_df[\"sid\"] = [x.split(\"=\")[1] for x in rmp_df.ratemyprof_sid]\n",
    "\n",
    "df = pd.merge(left = df.reset_index().drop(\"index\", axis = 1),\n",
    "              right = rmp_df.reset_index().drop(\"index\", axis = 1),\n",
    "              how = \"left\",\n",
    "              left_on = \"INSTNM\",\n",
    "              right_on = \"INSTNM\"\n",
    "             )\n",
    "# df.to_csv(data_pth) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Subset to include only GA schools\n",
    "\n",
    "subdf = df.loc[df[\"sid_y\"].isna() == False]\n",
    "\n",
    "subdf = subdf.rename(columns = {\"sid_y\": \"sid\"})\n",
    "\n",
    "print(len(subdf.sid.drop_duplicates().tolist()))\n",
    "\n",
    "subdf = subdf[subdf[\"STABBR\"] == \"GA\"]\n",
    "\n",
    "print(len(subdf.sid.drop_duplicates().tolist()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrape Rate My Professor\n",
    "\n",
    "ksu_sid = rmp_df[rmp_df[\"INSTNM\"] == \"Kennesaw State University\"].sid.iloc[0]\n",
    "school_results = get_school_reviews(ksu_sid)\n",
    "\n",
    "coun_ter = 0\n",
    "\n",
    "supdf_sid_list = [int(x) for x in subdf.sid.drop_duplicates().tolist()[coun_ter:]]\n",
    "\n",
    "for school_sid in supdf_sid_list:\n",
    "\n",
    "    if school_sid != ksu_sid:\n",
    "        temp = get_school_reviews(school_sid)\n",
    "        school_results = pd.concat([school_results, temp])\n",
    "        coun_ter = coun_ter + 1\n",
    "\n",
    "        if coun_ter % 5:\n",
    "            print(\"CHECKPOINT\")\n",
    "            print(\"NUMBER OF SCHOOLS LEFT:\", len(supdf_sid_list) - coun_ter)\n",
    "            print(\"NUMBER OF REVIEWS FOUND FOR MOST RECENT SCHOOL:\", temp.shape)\n",
    "            print(\"NUMBER OF REVIEWS FOUND TOTAL:\", school_results.shape)\n",
    "            school_results.to_csv(\"ratemyprof_reviews_IMPORTANT.csv\")\n",
    "\n",
    "# Scrape Rate My Professor - Alternative\n",
    "\n",
    "# school_results = pd.concat([get_school_reviews(school_sid) for school_sid in [int(x) for x in subdf.sid.drop_duplicates().tolist()[coun_ter:]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Save\n",
    "\n",
    "school_results.to_csv(fold_pth + output_data_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5210f08b43caa98193ac4cc30e63606a904c7d72d37a54875ef48f7a7b311874"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
